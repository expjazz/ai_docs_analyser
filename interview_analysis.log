2025-06-01 10:42:59,283 - INFO - Loaded existing file with 6 rows
2025-06-01 10:42:59,283 - INFO - Starting interview analysis...
2025-06-01 10:42:59,284 - INFO - Found 2 interview files
2025-06-01 10:42:59,284 - INFO - Found 5 already processed interviews
2025-06-01 10:42:59,284 - INFO - Processing Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx...
2025-06-01 10:42:59,286 - WARNING - Used latin-1 encoding for Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx
2025-06-01 10:43:00,582 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:43:00,582 - INFO - Retrying request to /chat/completions in 0.428923 seconds
2025-06-01 10:43:01,649 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:43:01,649 - INFO - Retrying request to /chat/completions in 0.878528 seconds
2025-06-01 10:43:02,822 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:43:02,825 - ERROR - Error analyzing Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx with OpenAI: Error code: 429 - {'error': {'message': 'Request too large for gpt-4 in organization org-uGSvxi6hqnDdr9iXzRd1jKay on tokens per min (TPM): Limit 10000, Requested 25529. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-06-01 10:43:02,825 - INFO - Processing Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx...
2025-06-01 10:43:02,828 - WARNING - Used latin-1 encoding for Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx
2025-06-01 10:43:03,396 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:43:03,397 - INFO - Retrying request to /chat/completions in 0.441391 seconds
2025-06-01 10:43:04,092 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:43:04,095 - INFO - Retrying request to /chat/completions in 0.942234 seconds
2025-06-01 10:43:05,347 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:43:05,348 - ERROR - Error analyzing Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx with OpenAI: Error code: 429 - {'error': {'message': 'Request too large for gpt-4 in organization org-uGSvxi6hqnDdr9iXzRd1jKay on tokens per min (TPM): Limit 10000, Requested 25658. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-06-01 10:43:05,348 - INFO - Processed 2 new interviews successfully
2025-06-01 10:43:05,400 - INFO - Results exported to Entrevistas Hospitais_Rosi.xlsx
2025-06-01 10:43:05,400 - INFO - Added 2 new interviews. Total: 8 interviews
2025-06-01 10:43:05,400 - INFO - Interview analysis completed successfully!
2025-06-01 10:46:01,113 - INFO - Loaded existing file with 8 rows
2025-06-01 10:46:01,113 - INFO - Starting interview analysis...
2025-06-01 10:46:01,114 - INFO - Found 2 interview files
2025-06-01 10:46:01,114 - INFO - Found 7 already processed interviews
2025-06-01 10:46:01,114 - INFO - Skipping Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx - already processed
2025-06-01 10:46:01,114 - INFO - Skipping Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx - already processed
2025-06-01 10:46:01,114 - INFO - Processed 0 new interviews successfully
2025-06-01 10:46:01,114 - ERROR - No interviews were processed successfully
2025-06-01 10:46:45,487 - INFO - Loaded existing file with 6 rows
2025-06-01 10:46:45,488 - INFO - Starting interview analysis...
2025-06-01 10:46:45,488 - INFO - Found 2 interview files
2025-06-01 10:46:45,488 - INFO - Found 5 already processed interviews
2025-06-01 10:46:45,488 - INFO - Processing Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx...
2025-06-01 10:46:45,489 - WARNING - Used latin-1 encoding for Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx
2025-06-01 10:46:45,489 - INFO - Estimated tokens for Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx: 16299
2025-06-01 10:46:45,489 - INFO - Content too large for Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx, chunking...
2025-06-01 10:46:45,490 - INFO - Split content into 3 chunks
2025-06-01 10:46:45,490 - INFO - Analyzing chunk 1/3 for Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx
2025-06-01 10:46:45,986 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-06-01 10:46:45,988 - ERROR - Error analyzing chunk 1 of Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 23016 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
2025-06-01 10:46:45,988 - INFO - Analyzing chunk 2/3 for Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx
2025-06-01 10:46:45,988 - INFO - Waiting 2 seconds to avoid rate limiting...
2025-06-01 10:46:48,474 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:46:48,476 - INFO - Retrying request to /chat/completions in 0.377081 seconds
2025-06-01 10:46:49,119 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:46:49,120 - INFO - Retrying request to /chat/completions in 0.944460 seconds
2025-06-01 10:46:50,315 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:46:50,317 - ERROR - Error analyzing chunk 2 of Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx: Error code: 429 - {'error': {'message': 'Request too large for gpt-4 in organization org-uGSvxi6hqnDdr9iXzRd1jKay on tokens per min (TPM): Limit 10000, Requested 17008. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-06-01 10:46:50,317 - INFO - Analyzing chunk 3/3 for Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx
2025-06-01 10:46:50,317 - INFO - Waiting 2 seconds to avoid rate limiting...
2025-06-01 10:46:52,500 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:46:52,503 - INFO - Retrying request to /chat/completions in 2.844000 seconds
2025-06-01 10:46:55,575 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-06-01 10:46:55,577 - ERROR - Error analyzing chunk 3 of Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, you requested 8249 tokens (6249 in the messages, 2000 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
2025-06-01 10:46:55,577 - INFO - Successfully analyzed Gravação da Entrevista - Gravador - 09_04_2025 - HAOC01 - Bruna e Nídia.docx using 3 chunks
2025-06-01 10:46:55,577 - INFO - Processing Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx...
2025-06-01 10:46:55,579 - WARNING - Used latin-1 encoding for Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx
2025-06-01 10:46:55,579 - INFO - Estimated tokens for Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx: 16297
2025-06-01 10:46:55,579 - INFO - Content too large for Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx, chunking...
2025-06-01 10:46:55,580 - INFO - Split content into 4 chunks
2025-06-01 10:46:55,580 - INFO - Analyzing chunk 1/4 for Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx
2025-06-01 10:46:55,751 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:46:55,751 - INFO - Retrying request to /chat/completions in 0.463606 seconds
2025-06-01 10:46:56,403 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:46:56,405 - INFO - Retrying request to /chat/completions in 0.771491 seconds
2025-06-01 10:46:57,397 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:46:57,397 - ERROR - Error analyzing chunk 1 of Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx: Error code: 429 - {'error': {'message': 'Request too large for gpt-4 in organization org-uGSvxi6hqnDdr9iXzRd1jKay on tokens per min (TPM): Limit 10000, Requested 10310. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-06-01 10:46:57,397 - INFO - Analyzing chunk 2/4 for Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx
2025-06-01 10:46:57,397 - INFO - Waiting 2 seconds to avoid rate limiting...
2025-06-01 10:46:59,574 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:46:59,574 - INFO - Retrying request to /chat/completions in 29.736000 seconds
2025-06-01 10:47:29,753 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-06-01 10:47:29,754 - ERROR - Error analyzing chunk 2 of Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 14184 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
2025-06-01 10:47:29,754 - INFO - Analyzing chunk 3/4 for Transcrição da entrevista corrigida 08_04_2025 - HIAE02 - Renato Tanjoni e Fernanda Pahim.docx
2025-06-01 10:47:29,754 - INFO - Waiting 2 seconds to avoid rate limiting...
2025-06-01 10:47:31,993 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 10:47:31,994 - INFO - Retrying request to /chat/completions in 44.034000 seconds
